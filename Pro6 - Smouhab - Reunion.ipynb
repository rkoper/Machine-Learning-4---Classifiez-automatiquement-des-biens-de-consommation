{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1051\n",
      "temps de traitement #IMG 1 - model_savepath :  0.0 minutes\n",
      "temps de traitement #IMG 2 - Tes-Train CNN  :  0.0 minutes\n",
      "temps de traitement #IMG 3 - train_datagen :  0.0 minutes\n",
      "Found 672 validated image filenames belonging to 7 classes.\n",
      "temps de traitement #IMG 4 - train_generator :  0.0 minutes\n",
      "temps de traitement #IMG 5 - train_labels :  0.0 minutes\n",
      "Found 168 validated image filenames belonging to 7 classes.\n",
      "temps de traitement #IMG 6 - valid_generator :  0.0 minutes\n",
      "(211, 2)\n",
      "temps de traitement #IMG 7 - df_test :  0.0 minutes\n",
      "temps de traitement #IMG 8 - test_datagen :  0.0 minutes\n",
      "Found 210 validated image filenames.\n",
      "temps de traitement #IMG 9 - test_generator :  0.0 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/logging/__init__.py\", line 1081, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/logging/__init__.py\", line 925, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/logging/__init__.py\", line 664, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/logging/__init__.py\", line 369, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n",
      "    self.do_execute(\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2877, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2923, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3146, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-3c738ba9f650>\", line 76, in <module>\n",
      "    train_generator = train_datagen.flow_from_dataframe(\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/keras/preprocessing/image.py\", line 1077, in flow_from_dataframe\n",
      "    tf_logging.warn(\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tensorflow/python/platform/tf_logging.py\", line 173, in warn\n",
      "    get_logger().warning(msg, *args, **kwargs)\n",
      "Message: 'has_ext is deprecated, filenames in the dataframe have to match the exact filenames in disk.'\n",
      "Arguments: (<class 'DeprecationWarning'>,)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/logging/__init__.py\", line 1081, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/logging/__init__.py\", line 925, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/logging/__init__.py\", line 664, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/logging/__init__.py\", line 369, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n",
      "    self.do_execute(\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2877, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2923, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3146, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-3c738ba9f650>\", line 96, in <module>\n",
      "    train_datagen.flow_from_dataframe(\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/keras/preprocessing/image.py\", line 1077, in flow_from_dataframe\n",
      "    tf_logging.warn(\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tensorflow/python/platform/tf_logging.py\", line 173, in warn\n",
      "    get_logger().warning(msg, *args, **kwargs)\n",
      "Message: 'has_ext is deprecated, filenames in the dataframe have to match the exact filenames in disk.'\n",
      "Arguments: (<class 'DeprecationWarning'>,)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/logging/__init__.py\", line 1081, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/logging/__init__.py\", line 925, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/logging/__init__.py\", line 664, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/logging/__init__.py\", line 369, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n",
      "    self.do_execute(\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2877, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2923, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3146, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-3c738ba9f650>\", line 121, in <module>\n",
      "    test_datagen.flow_from_dataframe(\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/keras/preprocessing/image.py\", line 1077, in flow_from_dataframe\n",
      "    tf_logging.warn(\n",
      "  File \"/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/tensorflow/python/platform/tf_logging.py\", line 173, in warn\n",
      "    get_logger().warning(msg, *args, **kwargs)\n",
      "Message: 'has_ext is deprecated, filenames in the dataframe have to match the exact filenames in disk.'\n",
      "Arguments: (<class 'DeprecationWarning'>,)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ResNet50' from 'keras.applications' (/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/keras/applications/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3c738ba9f650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ResNet50' from 'keras.applications' (/opt/anaconda3/envs/baseNew/lib/python3.8/site-packages/keras/applications/__init__.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from os import listdir\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import preprocessing\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Flatten,Conv2D, MaxPooling2D,Flatten, Dense, Dropout\n",
    "\n",
    "#import tensorflow as tf\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "\n",
    "#import logging\n",
    "##logger = logging.getLogger()\n",
    "#logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "import os\n",
    "\n",
    "#Path-----\n",
    "\n",
    "path = \"new_img/\"\n",
    "list_photos = [file for file in listdir(path)]\n",
    "print(len(list_photos))\n",
    "\n",
    "import time\n",
    "tempsX = time.time()\n",
    "def _time_(x):\n",
    "    duration1 = time.time()-tempsX\n",
    "    return print(\"temps de traitement \"+ str(x) + \" : \",  round(duration1/60,2), \"minutes\")\n",
    "\n",
    "\n",
    "mA = pd.read_csv('mDataImgName.csv')\n",
    "mB = pd.read_csv('mDataImgNumm.csv')\n",
    "mC = pd.read_csv('mDataImgCat.csv')\n",
    "\n",
    "df = mA.join(mB)\n",
    "df = df.join(mC)\n",
    "df = df.rename(columns={'img_name': 'id','Img_Cat_' : 'label', 'img_Num' : 'num'})\n",
    "\n",
    "model_savepath    = 'cnn_vgg16_model_trained_2.h5'     \n",
    "\n",
    "TRAINING_DIR      = 'img_train_/'\n",
    "TESTING_DIR       = 'img_test_/'\n",
    "\n",
    "IMGSIZE       = 224    # Taille de l'image en input\n",
    "EPOCH         = 22     # nombre d'epoch \n",
    "BATCH_SIZE    = 16     # traitement par batch d'images avant la descente de gradient\n",
    "FREEZE_LAYERS = 15     # pour un VGG16 freeze de réapprentissage de certaines couches\n",
    "TRAIN         = True \n",
    "\n",
    "_time_(\"#IMG 1 - model_savepath\")\n",
    "\n",
    "_count = df.num < 210\n",
    "df_test = df[_count]\n",
    "count_ = df.num >= 210\n",
    "df_train = df[ count_]\n",
    "\n",
    "_time_(\"#IMG 2 - Tes-Train CNN \")\n",
    "\n",
    "train_datagen =  ImageDataGenerator(preprocessing_function=preprocess_input,validation_split=0.20)\n",
    "_time_(\"#IMG 3 - train_datagen\")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "            df_train,\n",
    "            TRAINING_DIR,\n",
    "            x_col='id',\n",
    "            y_col='label',\n",
    "            has_ext=True,\n",
    "            shuffle=True,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            subset='training',\n",
    "            class_mode='categorical')\n",
    "\n",
    "_time_(\"#IMG 4 - train_generator\")\n",
    "\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "train_labels = to_categorical(train_generator.classes)\n",
    "_time_(\"#IMG 5 - train_labels\")\n",
    "\n",
    "valid_generator = \\\n",
    "        train_datagen.flow_from_dataframe(\n",
    "            df_train,\n",
    "            TRAINING_DIR,\n",
    "            x_col='id',\n",
    "            y_col='label',\n",
    "            has_ext=True,\n",
    "            shuffle=True,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            subset='validation',\n",
    "            class_mode='categorical')\n",
    "\n",
    "_time_(\"#IMG 6 - valid_generator\")\n",
    "\n",
    "test_files = os.listdir(TESTING_DIR)\n",
    "df_test = pd.DataFrame({\"id\": test_files, 'label': 'nan'})\n",
    "print(df_test.shape)\n",
    "\n",
    "_time_(\"#IMG 7 - df_test\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)    \n",
    "\n",
    "_time_(\"#IMG 8 - test_datagen\")\n",
    "\n",
    "test_generator = \\\n",
    "    test_datagen.flow_from_dataframe(\n",
    "        df_test, \n",
    "        TESTING_DIR, \n",
    "        x_col='id',\n",
    "        y_col=None, \n",
    "        has_ext=True, \n",
    "        target_size=(IMGSIZE, IMGSIZE), \n",
    "        class_mode=None, \n",
    "        seed=42,\n",
    "        batch_size=1, \n",
    "        shuffle=False  )\n",
    "\n",
    "_time_(\"#IMG 9 - test_generator\")\n",
    "\n",
    "\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "base_model = Sequential()\n",
    "base_model.add(ResNet50(include_top=False, pooling='avg'))\n",
    "base_model.add(Dense(7, activation='softmax'))\n",
    "base_model.layers[0].trainable = False\n",
    "base_model.summary()\n",
    "\n",
    "_time_(\"#IMG 10 - test_generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test trouve DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "\n",
    "_time_(\"#IMG 11 - base_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.fit_generator(\n",
    "                 generator=train_generator,\n",
    "                 steps_per_epoch = 30,\n",
    "                 validation_data = valid_generator,\n",
    "                 validation_steps = 10,\n",
    "                 epochs = 5)\n",
    "     \n",
    "_time_(\"#IMG 12 - history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation du modèle\n",
    "(eval_loss, eval_accuracy) = base_model.evaluate_generator(generator=valid_generator, steps=30)\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
    "print(\"[INFO] Loss: {}\".format(eval_loss))\n",
    "\n",
    "_time_(\"#IMG 13 - Evaluation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Test Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.keras.preprocessing.image.load_img('/Users/rogerrabbit/Desktop/Projet 6 Files/new_img/10-Watches.jpg')\n",
    "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "print(input_arr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst_pred = []\n",
    "st = '/Users/rogerrabbit/Desktop/Projet 6 Files/new_img/'\n",
    "for i in range (90,95):\n",
    "    image = tf.keras.preprocessing.image.load_img(st+ str(i) + '-Home_Decor_Festive_Needs.jpg',target_size=(224,224))\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "    predictions = base_model.predict(input_arr)\n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    print(predictions)\n",
    "    \n",
    "print(\"=================================\")\n",
    "    \n",
    "lst_pred = []\n",
    "st = '/Users/rogerrabbit/Desktop/Projet 6 Files/new_img/'\n",
    "for i in range (5,15):\n",
    "    image = tf.keras.preprocessing.image.load_img(st+ str(i) + '-Watches.jpg',target_size=(224,224))\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "    predictions = base_model.predict(input_arr)\n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = '/Users/rogerrabbit/Desktop/Projet 6 Files/new_img/9-Watches.jpg'\n",
    "\n",
    "image = tf.keras.preprocessing.image.load_img(st,target_size=(224,224))\n",
    "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "input_arr_ = np.array([input_arr])  # Convert single image to a batch.\n",
    "predictions = base_model.predict(input_arr_)\n",
    "predictions = pd.DataFrame(predictions)\n",
    "print(input_arr_.shape)\n",
    "print(input_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_generator\n",
    "\n",
    "\n",
    "\n",
    "_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base\n",
    "from IPython.display import Audio\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Graph\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "# Loop compteur\n",
    "# Warning\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "# Notif audio\n",
    "import time\n",
    "tempsX = time.time()\n",
    "def _time_(x):\n",
    "    duration1 = time.time()-tempsX\n",
    "    return print(\"temps de traitement \"+ str(x) + \" : \",  round(duration1/60,2), \"minutes\")\n",
    "\n",
    "def mFinito():\n",
    "    display(Audio('/Users/soso/Downloads/son_multiplex_canal_plus.mp3', autoplay=True))\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# Notif Chrome\n",
    "#%load_ext jupyternotify\n",
    "# Largeur colonne\n",
    "#pd.set_option('max_colwidth', 200)\n",
    "# df create\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def _df_(x):\n",
    "    return pd.DataFrame(x)\n",
    "\n",
    "#Add\n",
    "import gensim\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import gensim\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "X = pd.read_csv('m_x_df_TXT.csv')\n",
    "y = pd.read_csv('m_y_df_TXT.csv')\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "_time_(\"#TXT 1 - import_img_\")\n",
    "\n",
    "_time_(\"#TXT 2 - _create_X_\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=21)\n",
    "\n",
    "print('Shape of training data: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Shape of test data: ')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "_time_(\"#TXT 3 - train_test_split\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import LSTM, SpatialDropout1D\n",
    "\n",
    "\n",
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "\n",
    "print('X.shape[1]------', X.shape[1])\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "_time_(\"#TXT 4 - compile\")\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1)\n",
    "\n",
    "_time_(\"#TXT 5 - model.fit(\")\n",
    "\n",
    "\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# Displays the accuracy of correct sentiment prediction over test data\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "_time_(\"#TXT 6 - model.evaluate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# Displays the accuracy of correct sentiment prediction over test data\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "_time_(\"#TXT 6 - model.evaluate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('m_x_df_TXT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.layers import Input\n",
    "#from keras import layers\n",
    "#tag_input = Input(shape=(None,), dtype='int32', name='tag')\n",
    "#embedded_tag = layers.Embedding(50000, 100)(tag_input)\n",
    "#encoded_tag = layers.LSTM(256)(embedded_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reunion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=True, weights='imagenet', input_tensor=None,\n",
    "    input_shape=None, pooling=None, classes=1000)\n",
    "\n",
    "a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "mA = pd.read_csv('mDataImgName.csv')\n",
    "mB = pd.read_csv('mDataImgLab.csv')\n",
    "mC = pd.read_csv('mDataImgCat.csv')\n",
    "data = mA.join(mB)\n",
    "data = data.join(mC)\n",
    "data = data.rename(columns={'img_name': 'image_path','Img_Cat_label' : 'label', 'Img_Cat_' : 'label_name'})\n",
    "lst_img = []\n",
    "\n",
    "\n",
    "for xXx in tqdm(data.image_path):\n",
    "    image = tf.keras.preprocessing.image.load_img(\"new_img/\" + str(xXx) ,target_size=(224,224))\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    lst_img.append(input_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_img = np.array(lst_img)\n",
    "lst_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_txt = pd.read_csv('m_x_df_TXT.csv')\n",
    "lst_label = pd.read_csv('m_y_df_TXT.csv')\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_txt = lst_txt.to_numpy()\n",
    "lst_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tR_txt, X_tE_txt, y_tR_txt, y_tE_txt = train_test_split(lst_txt, lst_label, test_size=0.3,random_state=21)\n",
    "\n",
    "X_tR_img, X_tE_img, y_tR_img, y_tE_img = train_test_split(lst_img, lst_label, test_size=0.3,random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_input = Input(shape=(None,), dtype='int32', name='tag')\n",
    "m_txt = Embedding(5000, 100)(tag_input)\n",
    "m_txt = LSTM(512)(m_txt)\n",
    "m_txt = Dense(7, activation='relu')(m_txt)\n",
    "m_txt.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated = concatenate([m_txt, m_img], axis=-1)\n",
    "output = Dense(7, activation='sigmoid')(concatenated)\n",
    "model = Model([image_input, tag_input], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_tR_img.shape)\n",
    "print(X_tR_txt.shape)\n",
    "print(y_tE_txt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc']) \n",
    "model.fit([X_tR_img, X_tR_txt], y_tE_txt, epochs=30, batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------ TEST -------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model(input1, input2):\n",
    "   \n",
    "    input1 = np.expand_dims(input1,1)\n",
    "    input2 = np.expand_dims(input2, 1)\n",
    "\n",
    "    # Define Input Layers for ANN\n",
    "    input1 = Input(shape = (input1.shape[1],), name = \"input1\")\n",
    "    input2 = Input(shape = (input2.shape[1],), name = \"input2\")\n",
    "\n",
    "    inputs = [input1, input2]\n",
    "\n",
    "    # First Branch of DNN (input1)\n",
    "    x = BatchNormalization()(input1) \n",
    "    x = Dense(units = 5, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "\n",
    "    # Second Branch of DNN (input2)\n",
    "    y = BatchNormalization()(input2)  \n",
    "    y = Dense(units = 256, activation = \"relu\", kernel_regularizer=regularizers.l2(0.01))(y)\n",
    "    \n",
    "    #Third Branch of DNN (Detergents)\n",
    "    z = BatchNormalization()(input3) \n",
    "    z = Dense(units = 5, activation='relu', kernel_regularizer=regularizers.l2(0.01))(z)\n",
    "\n",
    "    # Merge the input models into a single large vector\n",
    "    concatenated = Concatenate()([x, y, z])\n",
    "    \n",
    "    #Apply Final Output Layer\n",
    "    outputs = Dense(32, activation = \"relu\",  kernel_regularizer=regularizers.l2(0.01))(concatenated)\n",
    "    outputs = Dropout(0.08)(outputs)\n",
    "    outputs = Dense(1, name = \"output\")(outputs)\n",
    "\n",
    "    # Create an Interpretation Model (Accepts the inputs from previous branches and has single output)\n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    \n",
    "    # Compile the Model\n",
    "    model.compile(loss='mse', optimizer = Adam(lr = 0.00001), metrics = ['mse'])\n",
    "\n",
    "    # Summarize the Model Summary\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#base_model = tf.keras.Sequential()\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "base_model = ResNet50(include_top=False, pooling='avg')\n",
    "conv1 = Conv2D(32, (3,3), activation = 'relu')(base_model.output)\n",
    "pool1 = MaxPooling2D(2,2)(conv1)\n",
    "bn1 = BatchNormalization(axis=chanDim)(pool1)\n",
    "drop1 = Dropout(0.2)(bn1)\n",
    "flatten1 = Flatten()(drop1)\n",
    "fc2 = Dense(classes, activation='softmax')(flatten1)\n",
    "base_model = Model(inputs=base_model.input, outputs=fc2)\n",
    "base_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_time_(\"#IMG 10 - test_generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "base_model = tf.keras.Sequential()\n",
    "\n",
    "emb = layers.Embedding(5000, 1000, input_length=10)\n",
    "spac = layers.SpatialDropout1D(0.2)\n",
    "lstm = layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2)\n",
    "dens = layers.Dense(7, activation='softmax')\n",
    "\n",
    "base_model = tf.keras.Sequential()\n",
    "base_model.add(emb)\n",
    "base_model.add(spac)\n",
    "base_model.add(lstm)\n",
    "base_model.add(dens)\n",
    "\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated = concatenate([model, base_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.layers import Embedding, SpatialDropout1D, LSTM,Conv2D, Dense\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 1000, input_length=10))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "model1_in = Input(shape=(27, 27, 1))\n",
    "model1_out = Dense(300, input_dim=40, activation='relu', name='layer_1')(model1_in)\n",
    "model1 = Model(model1_in, model1_out)\n",
    "\n",
    "model2_in = Input(shape=(27, 27, 1))\n",
    "model2_out = Dense(300, input_dim=40, activation='relu', name='layer_2')(model2_in)\n",
    "model2 = Model(model2_in, model2_out)\n",
    "\n",
    "\n",
    "concatenated = concatenate([model1_out, model2_out])\n",
    "out = Dense(1, activation='softmax', name='output_layer')(concatenated)\n",
    "\n",
    "merged_model = Model([model1_in, model2_in], out)\n",
    "merged_model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights.h5', monitor='val_acc',\n",
    "save_best_only=True, verbose=2)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "merged_model.fit([x1, x2], y=y, batch_size=384, epochs=200,\n",
    "             verbose=1, validation_split=0.1, shuffle=True, \n",
    "callbacks=[early_stopping, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text\n",
    "\n",
    "X = pd.read_csv('m_x_df_TXT.csv')\n",
    "y = pd.read_csv('m_y_df_TXT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "num_classes = 10\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "encoder_input = tf.keras.layers.Input(shape=(32, 32, 3), name=\"input\")\n",
    "x = tf.keras.layers.Conv2D(16, 3,activation = 'relu', kernel_initializer = keras.initializers.RandomUniform)(encoder_input)\n",
    "x = tf.keras.layers.Conv2D(32, 3, activation = 'relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(3)(x)\n",
    "x = tf.keras.layers.Conv2D(32, 3,activation = 'relu')(x)\n",
    "x = tf.keras.layers.Conv2D(16, 3, activation = 'relu')(x)\n",
    "encoder_output = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "encoder = tf.keras.Model(inputs=encoder_input, outputs=encoder_output, name = 'encoder')\n",
    "encoder.summary()\n",
    "\n",
    "#Decoder\n",
    "decoder_input = tf.keras.layers.Reshape((4, 4, 1))(encoder_output)\n",
    "x = tf.keras.layers.Conv2DTranspose(16, 3, activation = 'relu')(decoder_input)\n",
    "x = tf.keras.layers.Conv2DTranspose(32, 3, activation = 'relu')(x)\n",
    "x = tf.keras.layers.UpSampling2D(3)(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(16, 3, activation = 'relu')(x)\n",
    "decoder_output = tf.keras.layers.Conv2DTranspose(1, 3, activation = 'relu')(x)\n",
    "\n",
    "\n",
    "autoencoder = keras.Model(inputs = encoder_input, outputs = decoder_output, name='autoencoder')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.applications import ResNet50\n",
    "base_model = Sequential()\n",
    "base_model.add(ResNet50(include_top=False, pooling='avg'))\n",
    "base_model.add(Dense(7, activation='softmax'))\n",
    "base_model.layers[0].trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, SpatialDropout1D, LSTM,Conv2D, Dense\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 100, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model A\n",
    "\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "model1_in = Input(shape=(224, 224, 3))\n",
    "model1_in = (ResNet50(include_top=False, pooling='avg'))(model1_in)\n",
    "model1_out = Dense(7, input_dim=40, activation='relu', name='layer_1')(model1_in)\n",
    "model1_out\n",
    "model1_out.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model2_in = Input(shape=(None, 10))\n",
    "model2_out = Dense(300, input_dim=40, activation='relu', name='layer_2')(model2_in)\n",
    "model2 = Model(model2_in, model2_out)\n",
    "\n",
    "\n",
    "concatenated = concatenate([model1_out, model2_out])\n",
    "out = Dense(1, activation='softmax', name='output_layer')(concatenated)\n",
    "\n",
    "merged_model = Model([model1_in, model2_in], out)\n",
    "merged_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "model1_in = Input(shape=((224, 224, 3))\n",
    "model1_out = Dense(300, input_dim=40, activation='relu', name='layer_1')(model1_in)\n",
    "model1 = Model(model1_in, model1_out)\n",
    "\n",
    "model2_in = Input(shape=(27, 27, 1))\n",
    "model2_out = Dense(300, input_dim=40, activation='relu', name='layer_2')(model2_in)\n",
    "model2 = Model(model2_in, model2_out)\n",
    "\n",
    "\n",
    "concatenated = concatenate([model1_out, model2_out])\n",
    "out = Dense(1, activation='softmax', name='output_layer')(concatenated)\n",
    "\n",
    "merged_model = Model([model1_in, model2_in], out)\n",
    "merged_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated = layers.concatenate([x, encoded_tag], axis=-1)\n",
    "output = layers.Dense(1, activation='sigmoid')(concatenated)model = Model([image_input, tag_input], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
